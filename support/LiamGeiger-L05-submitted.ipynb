{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSG Assignment\n",
    "\n",
    "We already did some hyper-parameter tuning in previous lectures, but we were a little loose about how we did it: (1) we didn't use a validation data like we should have, and (2) we had to write a lot of custom-code to collected results. If we try a few different models we can get away with being a little sloppy, but now we're going to do things right. You should not be surprised to find out that hyper-parameter tuning being a common ML task, there's functionality in `sklearn` to help us with it. In this assignment, we are going to use it to try different combinations of hyper-parameters for the SVM classifier we trained in the lecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load and pre-process the data in the same way we did in the lecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# used 1/16 of the data to debug and 1/4 of the data to train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size is reduced from  (45211, 17)  to  (11302, 17)\n",
      "Featurized training data has 10171 rows and 51 columns.\n",
      "Featurized test data has 1131 rows and 51 columns.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_admin.</th>\n",
       "      <th>job_blue-collar</th>\n",
       "      <th>job_entrepreneur</th>\n",
       "      <th>job_housemaid</th>\n",
       "      <th>job_management</th>\n",
       "      <th>job_retired</th>\n",
       "      <th>job_self-employed</th>\n",
       "      <th>job_services</th>\n",
       "      <th>job_student</th>\n",
       "      <th>job_technician</th>\n",
       "      <th>...</th>\n",
       "      <th>poutcome_other</th>\n",
       "      <th>poutcome_success</th>\n",
       "      <th>poutcome_unknown</th>\n",
       "      <th>age</th>\n",
       "      <th>balance</th>\n",
       "      <th>day</th>\n",
       "      <th>duration</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.871497</td>\n",
       "      <td>0.939251</td>\n",
       "      <td>0.387423</td>\n",
       "      <td>-0.350663</td>\n",
       "      <td>-0.562904</td>\n",
       "      <td>-0.413454</td>\n",
       "      <td>-0.291715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.268481</td>\n",
       "      <td>0.127069</td>\n",
       "      <td>-0.691799</td>\n",
       "      <td>0.923129</td>\n",
       "      <td>-0.562904</td>\n",
       "      <td>-0.413454</td>\n",
       "      <td>-0.291715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.156492</td>\n",
       "      <td>0.837510</td>\n",
       "      <td>0.747164</td>\n",
       "      <td>0.184865</td>\n",
       "      <td>-0.562904</td>\n",
       "      <td>2.397009</td>\n",
       "      <td>0.677903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.871497</td>\n",
       "      <td>-0.392126</td>\n",
       "      <td>-1.291367</td>\n",
       "      <td>-0.343012</td>\n",
       "      <td>-0.562904</td>\n",
       "      <td>-0.413454</td>\n",
       "      <td>-0.291715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.743473</td>\n",
       "      <td>-0.398419</td>\n",
       "      <td>0.267509</td>\n",
       "      <td>-0.916792</td>\n",
       "      <td>0.380153</td>\n",
       "      <td>-0.413454</td>\n",
       "      <td>-0.291715</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 51 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   job_admin.  job_blue-collar  job_entrepreneur  job_housemaid  \\\n",
       "0         0.0              0.0               0.0            0.0   \n",
       "1         0.0              0.0               0.0            0.0   \n",
       "2         0.0              0.0               0.0            0.0   \n",
       "3         1.0              0.0               0.0            0.0   \n",
       "4         0.0              0.0               0.0            0.0   \n",
       "\n",
       "   job_management  job_retired  job_self-employed  job_services  job_student  \\\n",
       "0             1.0          0.0                0.0           0.0          0.0   \n",
       "1             1.0          0.0                0.0           0.0          0.0   \n",
       "2             1.0          0.0                0.0           0.0          0.0   \n",
       "3             0.0          0.0                0.0           0.0          0.0   \n",
       "4             1.0          0.0                0.0           0.0          0.0   \n",
       "\n",
       "   job_technician  ...  poutcome_other  poutcome_success  poutcome_unknown  \\\n",
       "0             0.0  ...             0.0               0.0               1.0   \n",
       "1             0.0  ...             0.0               0.0               1.0   \n",
       "2             0.0  ...             0.0               0.0               0.0   \n",
       "3             0.0  ...             0.0               0.0               1.0   \n",
       "4             0.0  ...             0.0               0.0               1.0   \n",
       "\n",
       "        age   balance       day  duration  campaign     pdays  previous  \n",
       "0  0.871497  0.939251  0.387423 -0.350663 -0.562904 -0.413454 -0.291715  \n",
       "1 -0.268481  0.127069 -0.691799  0.923129 -0.562904 -0.413454 -0.291715  \n",
       "2  1.156492  0.837510  0.747164  0.184865 -0.562904  2.397009  0.677903  \n",
       "3  0.871497 -0.392126 -1.291367 -0.343012 -0.562904 -0.413454 -0.291715  \n",
       "4 -0.743473 -0.398419  0.267509 -0.916792  0.380153 -0.413454 -0.291715  \n",
       "\n",
       "[5 rows x 51 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bank = pd.read_csv(\"../data/bank-full-1.csv\", sep = \";\")\n",
    "\n",
    "# bank is too large for a grid search assignment.  We will speed up calculations by reducing the data set to 1/4\n",
    "OldShape = bank.shape\n",
    "bank = bank.sample(int(bank.shape[0]/4)) #changed to 16 while debugging\n",
    "print(\"Dataset size is reduced from \", OldShape, \" to \", bank.shape)\n",
    "\n",
    "num_cols = bank.select_dtypes(['integer', 'float']).columns\n",
    "cat_cols = bank.select_dtypes(['object']).drop(columns = \"y\").columns\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(bank.drop(columns = \"y\"), bank[\"y\"], \n",
    "                                                    test_size = 0.10, random_state = 42)\n",
    "\n",
    "X_train = X_train.reset_index(drop = True)\n",
    "X_test = X_test.reset_index(drop = True)\n",
    "\n",
    "onehoter = OneHotEncoder(sparse = False)\n",
    "onehoter.fit(X_train[cat_cols])\n",
    "onehot_cols = onehoter.get_feature_names(cat_cols)\n",
    "X_train_onehot = pd.DataFrame(onehoter.transform(X_train[cat_cols]), columns = onehot_cols)\n",
    "X_test_onehot = pd.DataFrame(onehoter.transform(X_test[cat_cols]), columns = onehot_cols)\n",
    "\n",
    "znormalizer = StandardScaler()\n",
    "znormalizer.fit(X_train[num_cols])\n",
    "X_train_norm = pd.DataFrame(znormalizer.transform(X_train[num_cols]), columns = num_cols)\n",
    "X_test_norm = pd.DataFrame(znormalizer.transform(X_test[num_cols]), columns = num_cols)\n",
    "\n",
    "X_train_featurized = X_train_onehot # add one-hot-encoded columns\n",
    "X_test_featurized = X_test_onehot   # add one-hot-encoded columns\n",
    "X_train_featurized[num_cols] = X_train_norm # add numeric columns\n",
    "X_test_featurized[num_cols] = X_test_norm   # add numeric columns\n",
    "\n",
    "del X_train_norm, X_test_norm, X_train_onehot, X_test_onehot\n",
    "\n",
    "print(\"Featurized training data has {} rows and {} columns.\".format(*X_train_featurized.shape))\n",
    "print(\"Featurized test data has {} rows and {} columns.\".format(*X_test_featurized.shape))\n",
    "\n",
    "X_train_featurized.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are three main ways to search the **hyper-parameter space**:\n",
    "\n",
    "- **Grid search:** tries every combination of hyper-parameters\n",
    "- **Random search:** tries a random subset of all combinations of hyper-parameters\n",
    "- **Bayesian optimization:** tries a subset of all combinations of hyper-parameters (like random search) but does so in a more intelligent way, based on trading off the need to **explore** (trying a part of the hyper-parameter space thus far unexplored) and the need to **exploit** (focusing on a part of the hyper-parameter space that thus far seems promising)\n",
    "\n",
    "We will use a grid search algorithm here, as implemented by the `GridSearchCV` function. As a bonus, the grid search algorithm uses cross-validation (CV) to evaluate the model. Cross-validation can slow down the process, but we can use a lower number of **folds** to speed it up.\n",
    "\n",
    "SVMs have two important **high-level hyper-parameters** and then some lower-level ones that depend on the high-level ones. The high-level hyper-parameters are `C`, `kernel`. Depending on the choice of `kernel`, we can also specify `degree` and `gamma`. You can read more about that [here](https://scikit-learn.org/stable/modules/svm.html#kernel-functions).\n",
    "\n",
    "In addition to the hyper-parameters mentioned above, `SVC` also has some important arguments such as `max_iter` and `class_weight`, or `cache_size` which we should be aware of.\n",
    "\n",
    "- Use `GridSearchCV` to train multiple `SVC` classifiers with different hyper-parameter combination. <span style=\"color:red\" float:right>[15 point]</span>\n",
    "  - The hyper-parameters you want to try are `kernel`, `C` and `gamma`. You should pick two different choices for each. \n",
    "  - For `SVC` setting `probability = True` slows down training considerably, so it's not a good idea to use it during grid search. (Instead, we can retrain the final model using the hyper-pramaters combinations that we found and set `probability = True` to if we need to get soft predictions but we won't worry about that here.) Increase the cache size to 1024\n",
    "  - We leave it to you to read the documentation for `SVC` to see what choices make sense. Morever, your grid search should perform 3-fold cross-validation to select the best model, execute 4 parallel jobs (n_jobs), and return the training score (return_train_score = True).\n",
    "  - It's best to avoid running everything in one line. So try to break your code into a few different steps to make it easy to follow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## your code goes here\n",
    "parameters = {'kernel':('linear', 'rbf'), 'C':[1, 10],'gamma':[1,10]}\n",
    "svc=SVC()\n",
    "clf = GridSearchCV(svc, parameters,n_jobs=4, return_train_score=True, cv=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- While coding and debugging, reduce your training dataset to an additional 1/4 of the rows.\n",
    "(After your code works, you can try the full dataset and then pick the model with the best combination of hyper-parameters: in this context, hyper-parameter tuning is often also referred to as **model selection**.)  \n",
    "- Run your grid search to train all the models. <span style=\"color:red\" float:right>[5 point]</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, estimator=SVC(), n_jobs=4,\n",
       "             param_grid={'C': [1, 10], 'gamma': [1, 10],\n",
       "                         'kernel': ('linear', 'rbf')},\n",
       "             return_train_score=True)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## your code goes here\n",
    "clf.fit(X_train_featurized, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the results generated form the work done by the grid search is stored in the `cv_results_` attribute. For example, if we want to know the combination of hyper-parameters that was tried in the 10th iteration, we can run `clf.cv_results_['params'][9]` (assuming the trained model is called `clf`) and if we wantc to know the cross-validated evaluation score for that 10th itearation, we can run `clf.cv_results_['mean_test_score'][9]`.\n",
    "\n",
    "Note that we need to be careful about terminology here. Unfortunately, the hyper-parameters are called `params` by `GridSearchCV`. But in ML **parameters** are the things that the algorithm learns from the data (such as the coefficients in the prediction equation), whereas **hyper-parameters** cannot be learned from the data, which is why we have to tune them by trying different combination. Also, the cross-validated score is called `mean_test_score` even though we are not using the test data to evaluate it. At least not during model selection. We will use the test data later to evaluate the final model.\n",
    "\n",
    "Present a data frame of the grid search parameters and the validation scores ('mean_test_score') <span style=\"color:red\" float:right>[5 point]</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.89538895, 0.880936  , 0.89538895, 0.8819192 , 0.89519229,\n",
       "       0.87916629, 0.89519229, 0.88182087])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.cv_results_['mean_test_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'C': 1, 'gamma': 1, 'kernel': 'linear'},\n",
       " {'C': 1, 'gamma': 1, 'kernel': 'rbf'},\n",
       " {'C': 1, 'gamma': 10, 'kernel': 'linear'},\n",
       " {'C': 1, 'gamma': 10, 'kernel': 'rbf'},\n",
       " {'C': 10, 'gamma': 1, 'kernel': 'linear'},\n",
       " {'C': 10, 'gamma': 1, 'kernel': 'rbf'},\n",
       " {'C': 10, 'gamma': 10, 'kernel': 'linear'},\n",
       " {'C': 10, 'gamma': 10, 'kernel': 'rbf'}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.cv_results_['params']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C</th>\n",
       "      <th>gamma</th>\n",
       "      <th>kernel</th>\n",
       "      <th>mean_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>linear</td>\n",
       "      <td>0.895389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>rbf</td>\n",
       "      <td>0.880936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>linear</td>\n",
       "      <td>0.895389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>rbf</td>\n",
       "      <td>0.881919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>linear</td>\n",
       "      <td>0.895192</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    C  gamma  kernel  mean_test_score\n",
       "0   1      1  linear         0.895389\n",
       "1   1      1     rbf         0.880936\n",
       "2   1     10  linear         0.895389\n",
       "3   1     10     rbf         0.881919\n",
       "4  10      1  linear         0.895192"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results=pd.DataFrame(clf.cv_results_['params'])\n",
    "results['mean_test_score']=clf.cv_results_['mean_test_score']\n",
    "results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C</th>\n",
       "      <th>gamma</th>\n",
       "      <th>kernel</th>\n",
       "      <th>mean_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>linear</td>\n",
       "      <td>0.895389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>linear</td>\n",
       "      <td>0.895389</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   C  gamma  kernel  mean_test_score\n",
       "0  1      1  linear         0.895389\n",
       "2  1     10  linear         0.895389"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.loc[results.mean_test_score==results.mean_test_score.max()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time to pull the best model. We can explicitly call the `clf.best_estimator_` method. However, calling `clf.best_estimator_` explicitly is not necessary: by calling `clf.estimator` it is **implied** that we are calling the best estimator. This means that if we call `clf.predict`, we would be using the best estimator to get predictions.\n",
    "\n",
    "- Get predictions on the training and test data for the best model. Finally, get the precision and recall of the best estimator to see how they compare to what we got from logistic regression during the lecture. <span style=\"color:red\" float:right>[5 point]</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision = 91% and recall = 98% on the training data.\n",
      "Precision = 94% and recall = 98% on the validation data.\n"
     ]
    }
   ],
   "source": [
    "## your code goes here\n",
    "y_hat_train=clf.predict(X_train_featurized)\n",
    "y_hat_test=clf.predict(X_test_featurized)\n",
    "precision_train = precision_score(y_train, y_hat_train, pos_label = 'no') * 100 #per piazza discussion changed to no for the positive outcome state\n",
    "precision_test = precision_score(y_test, y_hat_test, pos_label = 'no') * 100\n",
    "\n",
    "recall_train = recall_score(y_train, y_hat_train, pos_label = 'no') * 100\n",
    "recall_test = recall_score(y_test, y_hat_test, pos_label = 'no') * 100\n",
    "\n",
    "print(\"Precision = {:.0f}% and recall = {:.0f}% on the training data.\".format(precision_train, recall_train))\n",
    "print(\"Precision = {:.0f}% and recall = {:.0f}% on the validation data.\".format(precision_test, recall_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results from lecture\n",
    "Precision = 65% and recall = 35% on the training data.\n",
    "\n",
    "Precision = 63% and recall = 34% on the validation data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "By utilizing the grid search we managed to increase both the precision and recall on both the training and validation data. By utilizing parameters (C=1(happens to be the default), gamma=1, and kernel='linear') on this model compared to gamma = 'scale', cache_size = 1024 in the class notebook. The default cache_size is 200 and was used in the grid search model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trained a stand alone SVC model with probability=True to see how it outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1, gamma=1, kernel='linear')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1, gamma=1, kernel='linear', probability=True)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## trained a typical SVC model using the hyper parameters determined for fun an included probability =True to see what the outputs are\n",
    "parameters = {'kernel':('linear', 'rbf'), 'C':[1, 10],'gamma':[1,10]}\n",
    "svc_fin=SVC(kernel='linear',C=1,gamma=1,probability=True)\n",
    "svc_fin.fit(X_train_featurized, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_hat_train_final_probability \n",
      " [[0.93413699 0.06586301]\n",
      " [0.84846366 0.15153634]\n",
      " [0.85015186 0.14984814]\n",
      " [0.95022764 0.04977236]\n",
      " [0.96449301 0.03550699]]\n",
      "y_hat_train_final \n",
      " ['no' 'no' 'no' 'no' 'no']\n"
     ]
    }
   ],
   "source": [
    "y_hat_train_fin_prob=svc_fin.predict_proba(X_train_featurized)\n",
    "y_hat_train_fin=svc_fin.predict(X_train_featurized)\n",
    "print('y_hat_train_final_probability \\n',y_hat_train_fin_prob[:5])\n",
    "print('y_hat_train_final \\n',y_hat_train_fin[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End of assignment"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
