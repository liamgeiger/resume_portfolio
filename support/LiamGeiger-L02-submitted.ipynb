{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSG Assignment\n",
    "\n",
    "So far we have been studying time series that we generated using a pre-defined stochastic process, but now let's apply the models we have been working with on some real-world data. We will work with a data set which shows the consumption of chocolate, beer and electricity in Australia from 1958 to 1991."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The filename, directory name, or volume label syntax is incorrect.\n"
     ]
    }
   ],
   "source": [
    "pip install pmdarima"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import sin, pi\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy.random as nr\n",
    "\n",
    "import sklearn.linear_model as lm\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import statsmodels.graphics.tsaplots as splt\n",
    "import statsmodels.api as statsmodels\n",
    "import statsmodels.formula.api as sm\n",
    "import statsmodels.tsa.seasonal as sts\n",
    "import statsmodels.tsa.arima_process as arima_process\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from statsmodels.tsa.arima_model import ARIMA\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.rcParams['figure.figsize'] = [15, 5]\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def decomp_ts(ts, period, model = 'additive'):\n",
    "    res = sts.seasonal_decompose(ts, model = model, period = period)\n",
    "    return(pd.DataFrame({'ts': ts, 'trend': res.trend, 'seasonal': res.seasonal, 'resid': res.resid}, \n",
    "                        index = ts.index))\n",
    "\n",
    "def plot_acf_pacf(x, lags = 40):\n",
    "    x = x[x.notna()] # remove NAs\n",
    "    fig, axes = plt.subplots(1, 2, figsize = (15, 5))\n",
    "    fig = splt.plot_acf(x, lags = lags, ax = axes[0])\n",
    "    fig = splt.plot_pacf(x, lags = lags, ax = axes[1]);\n",
    "    return None\n",
    "\n",
    "def plot_ts_resid(x):\n",
    "    x = x[x.notna()] # remove NAs\n",
    "    fig, axes = plt.subplots(1, 2, figsize = (15, 5))\n",
    "    fig = sns.lineplot(x.index, x, ax = axes[0])\n",
    "    fig = sns.distplot(x, ax = axes[1]);\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>choc</th>\n",
       "      <th>beer</th>\n",
       "      <th>elec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1958-01-31</th>\n",
       "      <td>1451</td>\n",
       "      <td>96.3</td>\n",
       "      <td>1497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1958-02-28</th>\n",
       "      <td>2037</td>\n",
       "      <td>84.4</td>\n",
       "      <td>1463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1958-03-31</th>\n",
       "      <td>2477</td>\n",
       "      <td>91.2</td>\n",
       "      <td>1648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1958-04-30</th>\n",
       "      <td>2785</td>\n",
       "      <td>81.9</td>\n",
       "      <td>1595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1958-05-31</th>\n",
       "      <td>2994</td>\n",
       "      <td>80.5</td>\n",
       "      <td>1777</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            choc  beer  elec\n",
       "1958-01-31  1451  96.3  1497\n",
       "1958-02-28  2037  84.4  1463\n",
       "1958-03-31  2477  91.2  1648\n",
       "1958-04-30  2785  81.9  1595\n",
       "1958-05-31  2994  80.5  1777"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CBE = pd.read_csv('data/cbe.csv')\n",
    "CBE.index = pd.date_range(start = '1-1-1958', end = '12-31-1990', freq = 'M')\n",
    "\n",
    "CBE.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We limit our example to looking at beer consumption."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_ts_resid(CBE['beer'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that for each of these time series the amplitude of the seasonal variation grows with time. This is a common situation with real world data. Seeing this situation indicates that we should use a **multiplicative decomposition model**.  \n",
    "\n",
    "The multiplicative model can be easily transformed to an additive model by taking the logarithm of the values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "CBE['beer_log'] = np.log(CBE['beer'])\n",
    "plot_ts_resid(CBE['beer_log'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice the following properties about this time series.\n",
    "- It has a significant trend.\n",
    "- The time series have a noticeable seasonal component.\n",
    "- The magnitude of the seasonal component increases with trend in the un-transformed time series. \n",
    "- The seasonal component of the log transformed series has a nearly constant magnitude, but decreases a bit with time. \n",
    "\n",
    "These results indicate that an STL decomposition is required. Further, a multiplicative (log transformed) STL model is preferred.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitting linear regression\n",
    "\n",
    "Before training any time series model, let's see how our old fried linear regression does. In cases where the data is relatively well behaved, we can train a model using linear regression, but we need to do some pre-processing to account for the time series nature of the data. This can be a manual and laborious process, but going through it can give us a sense of what trying to model time series \"manually\" looks like.\n",
    "\n",
    "- Create a feature called `month_int`, which is equal to 1 when the month is January, 2 for February, and so on. Create another feature called `month_sqr` which is the square of `month_int`. <span style=\"color:red\" float:right>[2 point]</span>\n",
    "- One-hot-encode the `month_int` feature (creating one binary feature for each month), and normalize `month_int` and `month_sqr`. <span style=\"color:red\" float:right>[2 point]</span>\n",
    "- Create a feature called `beer_log_lag_1` which is the first lag of `beer_log` (as in the last known price of beer, when you look at the previous row). HINT: You can get lagged features using the `shift` method. <span style=\"color:red\" float:right>[2 point]</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>choc</th>\n",
       "      <th>beer</th>\n",
       "      <th>elec</th>\n",
       "      <th>beer_log</th>\n",
       "      <th>month_int</th>\n",
       "      <th>month_sqr</th>\n",
       "      <th>month_int_norm</th>\n",
       "      <th>month_sqr_norm</th>\n",
       "      <th>beer_log_lag_1</th>\n",
       "      <th>Month_1</th>\n",
       "      <th>...</th>\n",
       "      <th>Month_3</th>\n",
       "      <th>Month_4</th>\n",
       "      <th>Month_5</th>\n",
       "      <th>Month_6</th>\n",
       "      <th>Month_7</th>\n",
       "      <th>Month_8</th>\n",
       "      <th>Month_9</th>\n",
       "      <th>Month_10</th>\n",
       "      <th>Month_11</th>\n",
       "      <th>Month_12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1958-01-31</th>\n",
       "      <td>1451</td>\n",
       "      <td>96.3</td>\n",
       "      <td>1497</td>\n",
       "      <td>4.567468</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.591242</td>\n",
       "      <td>-1.151852</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1958-02-28</th>\n",
       "      <td>2037</td>\n",
       "      <td>84.4</td>\n",
       "      <td>1463</td>\n",
       "      <td>4.435567</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>-1.301925</td>\n",
       "      <td>-1.086857</td>\n",
       "      <td>4.567468</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1958-03-31</th>\n",
       "      <td>2477</td>\n",
       "      <td>91.2</td>\n",
       "      <td>1648</td>\n",
       "      <td>4.513055</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>-1.012609</td>\n",
       "      <td>-0.978533</td>\n",
       "      <td>4.435567</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1958-04-30</th>\n",
       "      <td>2785</td>\n",
       "      <td>81.9</td>\n",
       "      <td>1595</td>\n",
       "      <td>4.405499</td>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "      <td>-0.723292</td>\n",
       "      <td>-0.826878</td>\n",
       "      <td>4.513055</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1958-05-31</th>\n",
       "      <td>2994</td>\n",
       "      <td>80.5</td>\n",
       "      <td>1777</td>\n",
       "      <td>4.388257</td>\n",
       "      <td>5</td>\n",
       "      <td>25</td>\n",
       "      <td>-0.433975</td>\n",
       "      <td>-0.631894</td>\n",
       "      <td>4.405499</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            choc  beer  elec  beer_log  month_int  month_sqr  month_int_norm  \\\n",
       "1958-01-31  1451  96.3  1497  4.567468          1          1       -1.591242   \n",
       "1958-02-28  2037  84.4  1463  4.435567          2          4       -1.301925   \n",
       "1958-03-31  2477  91.2  1648  4.513055          3          9       -1.012609   \n",
       "1958-04-30  2785  81.9  1595  4.405499          4         16       -0.723292   \n",
       "1958-05-31  2994  80.5  1777  4.388257          5         25       -0.433975   \n",
       "\n",
       "            month_sqr_norm  beer_log_lag_1  Month_1  ...  Month_3  Month_4  \\\n",
       "1958-01-31       -1.151852             NaN        1  ...        0        0   \n",
       "1958-02-28       -1.086857        4.567468        0  ...        0        0   \n",
       "1958-03-31       -0.978533        4.435567        0  ...        1        0   \n",
       "1958-04-30       -0.826878        4.513055        0  ...        0        1   \n",
       "1958-05-31       -0.631894        4.405499        0  ...        0        0   \n",
       "\n",
       "            Month_5  Month_6  Month_7  Month_8  Month_9  Month_10  Month_11  \\\n",
       "1958-01-31        0        0        0        0        0         0         0   \n",
       "1958-02-28        0        0        0        0        0         0         0   \n",
       "1958-03-31        0        0        0        0        0         0         0   \n",
       "1958-04-30        0        0        0        0        0         0         0   \n",
       "1958-05-31        1        0        0        0        0         0         0   \n",
       "\n",
       "            Month_12  \n",
       "1958-01-31         0  \n",
       "1958-02-28         0  \n",
       "1958-03-31         0  \n",
       "1958-04-30         0  \n",
       "1958-05-31         0  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## your code goes here\n",
    "# part 1\n",
    "CBE['month_int']=CBE.index.month\n",
    "CBE['month_sqr']=CBE['month_int'].pow(2)\n",
    "# part 2\n",
    "dum = pd.get_dummies(CBE.month_int, prefix='Month')\n",
    "CBE['month_int_norm']=(CBE['month_int']-CBE['month_int'].mean())/CBE['month_int'].std()\n",
    "CBE['month_sqr_norm']=(CBE['month_sqr']-CBE['month_sqr'].mean())/CBE['month_sqr'].std()\n",
    "# part 3\n",
    "CBE['beer_log_lag_1']=CBE['beer_log'].shift(1)\n",
    "\n",
    "# combining everything back into the CBE data frame\n",
    "CBE=pd.concat([CBE, dum], axis=1)\n",
    "\n",
    "# displaying first 5 rows\n",
    "CBE.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the feature engineering steps we took, we should be able to train a linear regression model now. With `month_int` and `month_sqr` the model should be able to find a trend over the course of the year, which is either linear or curvelinear with a single peak or trough. By one-hot-encoding `month_int` the model can also capture month to month effects. Finally, using a lagged feature, the model can anchor its beer price prediction on the last known price.\n",
    "\n",
    "- Split the data into training and test sets, using the last 12 months of data for testing. <span style=\"color:red\" float:right>[2 point]</span> \n",
    "- Train a linear regression model to predict beer price using onely the features we created earlier. <span style=\"color:red\" float:right>[2 point]</span> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "# part 1 splitting the data\n",
    "train_CBE=CBE[:-13].bfill().ffill() # back-filling the beginning and forward-filling the ending as the first row contains a NaN value\n",
    "test_CBE=CBE[-13:-1] #use the last 12 months for testing\n",
    "## part 2 train a lin reg model to predict beer_log price\n",
    "Y = train_CBE['beer_log']\n",
    "#\n",
    "column=['month_int_norm','month_sqr_norm','beer_log_lag_1'] + list(dum.columns.values)\n",
    "X=train_CBE[column]\n",
    "#model initialization\n",
    "regression_model = LinearRegression()\n",
    "#fit the data(train)\n",
    "regression_model.fit(X,Y)\n",
    "#predict\n",
    "train_CBE['predicted_beer_log'] = regression_model.predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Plot a line plot of the original time series, and to the same plot add line plots to show the predictions on the training data and the test data. Use separate colors for each. <span style=\"color:red\" float:right>[3 point]</span> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1ca71ac0580>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## your code goes here\n",
    "# create test prediction\n",
    "test_CBE['predicted_beer_log'] = regression_model.predict(test_CBE[column]) #using same columns but test data frame\n",
    "# plots\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = plt.axes()\n",
    "plt.plot(CBE.index, CBE['beer_log']) # plot actual\n",
    "plt.plot(train_CBE.index, train_CBE['predicted_beer_log']) # plot predicted_train\n",
    "plt.plot(test_CBE.index, test_CBE['predicted_beer_log']) # plot predicted_test\n",
    "plt.title(\"Predicted Price of Beer v.s. Actual\")\n",
    "plt.xlabel(\"Year\")\n",
    "plt.ylabel(\"Price of Beer\");\n",
    "plt.legend(['Actual','Predicted_Train','Predicted_Test'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Compute the **root mean square error (RMSE)** of the model on the test data and plot the line plot and the histogram of the residual (beer price minus forecast) using the `plot_ts_resid` helper function. What conclusion would you draw about the model we fit? <span style=\"color:red\" float:right>[2 point]</span> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The RMSE is 0.0105\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "## your code goes here\n",
    "## part 0 use the model to predict based on the test data\n",
    "#test_CBE['predicted_beer'] = regression_model.predict(test_CBE[column])\n",
    "# part 1 calculate RMSE of the predicted test data\n",
    "rmse=mean_squared_error(y_true=test_CBE['beer_log'],y_pred=test_CBE['predicted_beer_log'])# using test data not training data\n",
    "print(f'The RMSE is {rmse:.4f}')\n",
    "# part 2 plot line plot/ histogram of resid\n",
    "plot_ts_resid(test_CBE['predicted_beer_log'])\n",
    "plot_ts_resid(test_CBE['beer_log'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusions\n",
    "\n",
    "By evaluating both the train and test model predictions against the actual we can see at a 10,000 foot level that the linear model is relatively accurate at prediction.  By doing additional calculation of the RMSE of the test_log data v.s. the test_log prediction we can see that the RMSE is 0.0101 which when compared to our values of ~4.2-5.3 is quite good and further strengthens our position that we have created a strong model. By evaluating the residuals of the test data v.s. the test prediction we can see that the residuals follow a similar shape with values ranging from ~4.9-5.35. Additionally the histogram shows the values are centered around 5.0 with a second peak at about 3.5.  All of the above leads us to believe the model created has a strong ability to accurately predict the beer_log price to a reasonable degree."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitting a time series model\n",
    "\n",
    "Let's now try the models we learned about in this lesson. By doing so, we can later compare the two approaches and appreciate the pros and cons.\n",
    "\n",
    "- Use the `decomp_ts` helper function to decompose `beer_log`. Remove the NAs from the data, then use the `plot` method to plot a line plot of the components. <span style=\"color:red\" float:right>[3 point]</span> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## your code goes here\n",
    "decomp = decomp_ts(CBE['beer_log'], period = 12).bfill().ffill() # use helper function and remove NaNs\n",
    "#plot\n",
    "decomp.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Compute and plot the ACF and PACF for the remainder (residual) series, up to 36 lags. <span style=\"color:red\" float:right>[2 point]</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## your code goes here\n",
    "plot_acf_pacf(decomp['resid'], lags = 36)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can imagine, with real data things can look very messy. The ACF and PACF can exhibit both AR and MA behavior and it's hard to know what degrees to choose. So we will use the `auto_arima` function to help us: It  iterates over a grid of $(p, d, q)$ and seasonal $(P, D, Q)$ values. For each combination the BIC is computed and compared to the best previous model. For each combination the BIC is computed and compared to the best previous model. The better model is the one with the lowest BIC: The **Bayesian information criteria (BIC)** is a measure for assessing a model's fit:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\text{BIC} &= \\ln(n)k - 2 \\ln(\\hat L)\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "where $\\hat L$ is the likelihood of the data given the fitted model parmaters, $k$ is the number of model parameters, and $n$ is the number of observations. Lower values for BIC means we have a better fit.\n",
    "\n",
    "The code below implements `auto_arima`. As you can see, we provide it with the data, some maximum value for the hyper-pramaters $(p, d, q)$ and $(P, D, Q)$. It's very unusual to choose a number greater than 3. Run the next cell and examine the results. The function returns the best model, i.e. the model whose hyper-parameters gave the lowest BIC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('1989-12-31 00:00:00', freq='M')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CBE.index[-13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pmdarima'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-9d093d40e035>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mvalidation_cut_off\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mCBE\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m13\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mpmdarima\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mauto_arima\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m best_fit = auto_arima(CBE.loc[:validation_cut_off, 'beer_log'], \n\u001b[0;32m      4\u001b[0m                       \u001b[0mmax_p\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_d\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_q\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m                       \u001b[0mm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m12\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_P\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_D\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_Q\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pmdarima'"
     ]
    }
   ],
   "source": [
    "validation_cut_off=CBE.index[-13]\n",
    "from pmdarima import auto_arima\n",
    "best_fit = auto_arima(CBE.loc[:validation_cut_off, 'beer_log'], \n",
    "                      max_p = 3, max_d = 1, max_q = 3, \n",
    "                      m = 12, max_P = 1, max_D = 1, max_Q = 1, \n",
    "                      information_criterion = 'bic', \n",
    "                      trace = True, error_action = 'ignore', suppress_warnings = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the best model's summary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(best_fit.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now visualize the forecast. With time series models we use the `predict_in_sample` to make predictions for the range of data that we used during training, and we use `predict` to make forecasts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#played around with some variable names to make things work with my code above.\n",
    "start_idx = 1\n",
    "train_idx = train_CBE.reset_index().index[start_idx:]\n",
    "n_periods = len(test_CBE)\n",
    "\n",
    "sns.lineplot(CBE.index, CBE['beer_log'], alpha = 0.3)\n",
    "sns.lineplot(train_CBE.index[train_idx], best_fit.predict_in_sample(start = start_idx, end = train_idx.max()))\n",
    "sns.lineplot(test_CBE.index, best_fit.predict(n_periods = n_periods))\n",
    "plt.legend(['original', 'fit', 'forecast']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how the predictions are initially a bit off, but overall the forecasts look reasonable.\n",
    "\n",
    "- Compute the RMSE and use `plot_ts_resid` to plot the line plot and the histogram of the residuals. How does the RMSE for this model compare the the linear regression model? <span style=\"color:red\" float:right>[2 point]</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## your code goes here\n",
    "# part 1 calculate RMSE of the predicted test data\n",
    "rmse=mean_squared_error(y_true=test_CBE['beer_log'],y_pred=best_fit.predict(n_periods = n_periods))# using test data not training data\n",
    "print(f'The RMSE is {rmse:.4f}')\n",
    "# part 2 plot line plot/ histogram of resid\n",
    "best_fit_predict=best_fit.predict(n_periods = n_periods) #need to change np array to pandas series for helper function to work\n",
    "plot_ts_resid(pd.Series(best_fit_predict, name='best_fit_log'))\n",
    "plot_ts_resid(test_CBE['predicted_beer_log'])\n",
    "plot_ts_resid(test_CBE['beer_log'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "The RMSE of this \"best_fit\" model(RMSE=0.0118) is slightly worse than (RMSE=0.0101) of the linear regression model. However by looking at the histogram charts the best_fit models residuals are more in line with the actual data. In either case both models perform relatively well and further data or testing will have to be completed to determine a clear winner. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We hope the assignment convinced you that the decision as to which model is better is not always clear. Of course we can rely on a metric like RMSE, but we don't want that to be the sole determinant. The level of familiarity with this or that algorithm should also be important. For example, we spent a lot of time learning about linear models, so even if the linear model is a slight worse fit we may prefer it because they are efficient and we can focus on feature engineering to improve its performance. ARIMA models on the other hand have the advantage of taking care of a lot of the feature engineering, but they are more difficult to explainr and require more experience in order to tune well. These sorts of trade-offs are very common in data science.\n",
    "\n",
    "# End of assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "306.6px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
